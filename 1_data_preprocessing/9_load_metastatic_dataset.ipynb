{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM6133738_RCC-BM10-Tumor.count.csv\n",
      "GSM6133739_RCC-BM10-Involve.count.csv\n",
      "GSM6133740_RCC-BM10-Noninvolved.count.csv\n",
      "GSM6133741_RCC-BM3-Tumor.count.csv\n",
      "GSM6133742_RCC-BM4-Tumor.count.csv\n",
      "GSM6133743_RCC-BM5-Tumor.count.csv\n",
      "GSM6133744_RCC-BM7-Tumor.count.csv\n",
      "GSM6133745_RCC-BM8-Tumor.count.csv\n",
      "GSM6133746_RCC-BM1-Tumor.count.csv\n",
      "GSM6133747_RCC-BM1-Involve.count.csv\n",
      "GSM6133748_RCC-BM1-Noninvolved.count.csv\n",
      "GSM6133749_RCC-BM2-Tumor.count.csv\n",
      "GSM6133750_RCC-BM2-Involve.count.csv\n",
      "GSM6133751_RCC-BM2-Noninvolved.count.csv\n",
      "GSM6133752_RCC-BM9-Involve.count.csv\n",
      "GSM6133753_RCC-BM9-Noninvolved.count.csv\n",
      "GSM6133754_RCC-BM9-Tumor.count.csv\n",
      "GSM6507003_BMM1-Benign-stroma.count.csv\n",
      "GSM6507004_BMM2-Benign-stroma.count.csv\n",
      "GSM6507005_BMM3-Benign-stroma.count.csv\n",
      "GSM6507006_BMM4-Benign-stroma.count.csv\n",
      "GSM6507007_BMM5-Benign-stroma.count.csv\n",
      "GSM6507008_BMM6-Benign-stroma.count.csv\n",
      "GSM6507009_BMM8-Benign-stroma.count.csv\n",
      "GSM6507010_BMM9-Benign-stroma.count.csv\n",
      "GSM6507011_BMM7-Benign-stroma.count.csv\n",
      "GSM6507012_BMM2-Benign-immune.count.csv\n",
      "GSM6507013_BMM3-Benign-immune.count.csv\n",
      "GSM6507014_BMM4-Benign-immune.count.csv\n",
      "GSM6507015_BMM5-Benign-immune.count.csv\n",
      "GSM6507016_BMM6-Benign-immune.count.csv\n",
      "GSM6507017_BMM8-Benign-immune.count.csv\n",
      "GSM6507018_BMM9-Benign-immune.count.csv\n",
      "Data shape: (98852, 96)\n",
      "Labels shape: (98852,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def make_df(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.set_index('...1')\n",
    "\n",
    "    target_genes = pd.read_csv(\"/home/sr933/rcc/data/Target_genes.csv\")\n",
    "\n",
    "    \n",
    "    # Assuming the Target_genes.csv contains a column named 'gene' with row indices\n",
    "    # Assuming df is your DataFrame and target_indices is the list of target gene names\n",
    "    target_indices = target_genes['Genes'].values  # Example, adjust this to your actual data\n",
    "\n",
    "    # Step 1: Identify which target genes are present in df.index\n",
    "    valid_target_indices = [gene for gene in target_indices if gene in df.index]\n",
    "    missing_target_indices = [gene for gene in target_indices if gene not in df.index]\n",
    "\n",
    "    # Step 2: Extract the rows for valid target genes\n",
    "    filtered_df = df.loc[valid_target_indices]\n",
    "\n",
    "    # Step 3: Add a row for each missing target gene with zero values (same number of columns as df)\n",
    "    for missing_gene in missing_target_indices:\n",
    "        zero_row = pd.Series(0, index=df.columns, name=missing_gene)\n",
    "        filtered_df = pd.concat([filtered_df, zero_row.to_frame().T])\n",
    "\n",
    "    # Step 4: Reorder the DataFrame to match the order of target_indices\n",
    "    filtered_df = filtered_df.loc[target_indices]\n",
    "    # Step 4: Concatenate the valid target genes and the missing genes (with zero values)\n",
    "\n",
    "    return filtered_df\n",
    "main_folder=\"/data/sr933/scRCC validation/GSE202813_RAW\"\n",
    "\n",
    "# Initialize lists to store data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop through files in the main folder\n",
    "for file in os.listdir(main_folder):\n",
    "    if \".gz\" in file:\n",
    "        continue\n",
    "    print(file)\n",
    "    data_path = os.path.join(main_folder, file)\n",
    "    \n",
    "    # Create a numpy array from the file\n",
    "    ar = make_df(data_path)  # Ensure `make_nparray` is properly implemented\n",
    "    data.append(ar.to_numpy().T)\n",
    "    \n",
    "    # Step 2: Extract column names from the first CSV\n",
    "    column_names = ar.columns\n",
    "    \n",
    "    # Step 2: Extract the base name of the first file (without extension)\n",
    "\n",
    "\n",
    "    # Step 3: Construct the path to the second CSV file\n",
    "    folder_path = \"/data/sr933/scRCC validation/GSE202813_RAW\"\n",
    "    second_csv_path = os.path.join(folder_path, file+\".gz_cell_annotation.csv\")\n",
    "\n",
    "    # Step 3: Read the second CSV file that contains the column names and cell-type labels\n",
    "    cell_type_data = pd.read_csv(second_csv_path)\n",
    "\n",
    "    # Step 4: Create a dictionary to map column names to labels\n",
    "    # Assuming the first column in the second CSV is the column name and the last column is the label\n",
    "    label_dict = pd.Series(cell_type_data.iloc[:, -1].values, index=cell_type_data.iloc[:, 0].values).to_dict()\n",
    "\n",
    "    # Step 5: Create a list of labels corresponding to the columns of ar\n",
    "    labels.append( [label_dict[column_name] for column_name in column_names])\n",
    "\n",
    "\n",
    "# Combine all data and labels into arrays\n",
    "data = np.concatenate(data, axis=0)\n",
    "labels = np.concatenate(labels)\n",
    "# Validate shapes\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "validation_data={\"X_test\": data, \"y_test\":labels}\n",
    "# Path to save the pickle file\n",
    "pickle_file_path = \"/data/sr933/scRCC validation/processed data/scRCC_validation_dataset_metastatic.pkl\"  # Update with your desired path\n",
    "\n",
    "# Save the validation_data dictionary as a pickle file\n",
    "with open(pickle_file_path, \"wb\") as pkl_file:\n",
    "    pickle.dump(validation_data, pkl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
